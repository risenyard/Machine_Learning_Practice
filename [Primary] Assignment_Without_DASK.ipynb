{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed592307-32e5-4391-b502-8f4d5e843490",
   "metadata": {},
   "source": [
    "# Graded Exercise #3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fd732c-15e9-4fae-a76c-90e95664ee62",
   "metadata": {},
   "source": [
    "[EuroSAT](https://zenodo.org/records/7711810#.ZAm3k-zMKEA) is a land use and land cover classification dataset. The dataset is based on Sentinel-2 satellite imagery covering 13 spectral bands and consists of 10 Land Use and Land Cover (LULC) classes with a total of 27,000 labeled and geo-referenced images. \n",
    "\n",
    "Using the following code, you can create a DataFrame that includes columns detailing the center locations of the images and their corresponding Land Use and Land Cover (LULC) classes.\n",
    "\n",
    "Our task: Perform **supervised Machine Learning (ML)** on this dataset. Later we will use **Dask** in your implementation. We will follow the following key steps:\n",
    "- Create relevant features and analyse them using some visualizations and statistical tools. You can start with features representing the mean and range of spectral bands in these images. You are free to explore more relevant features.\n",
    "- Split the dataset into training, validation, and test sets.\n",
    "- Choose an appropriate ML algorithm.\n",
    "- Train and assess the model's performance.\n",
    "- Adjust the model's hyperparameters to optimize its performance.\n",
    "\n",
    "**Points of discussion**:\n",
    "- Can you explain the criteria and rationale behind the features you created? What other features you would select from these images in addition to the mean and range? --> See section 2 of Assignement_Without_Dask\n",
    "- Why is it important to have separate sets for training, validation, and testing? Which split did you consider and why? --> See section 3 of Assignement_Without_Dask   \n",
    "- What factors influenced your choice of a specific machine learning algorithm? --> See section 4 of Assignement_Without_Dask    \n",
    "- How did hyperparameter tuning impact the model's performance, and what were the final hyperparameter settings? --> See section 5 of Assignement_Dask\n",
    "- What is the impact of using DASK to solve this problem? What is the impact of changing DASK parameters like chunk size? You may consider checking CPU, memory usage, processing time, ... --> See section 6 of Assignement_Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a5c7c1-1390-40ce-a14b-51a5c59b3ccf",
   "metadata": {},
   "source": [
    "## 1. Creating the work space\n",
    "Import all the relevant folders and include the file path to the where the imagery data are. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a3821-c18c-4cbd-b5a7-11e948817e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import rasterio.features\n",
    "import rasterio.warp\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83a247-7c78-4869-8e5c-5347b1e844c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8077d511-76fa-40e6-8bbd-41af4642a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'EuroSAT_MS/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1ae1a-ffa6-44cb-bcd2-9fe03aa7c6fa",
   "metadata": {},
   "source": [
    "## 2. Creating target variable data frame and relevant features\n",
    "The goal of this excersize is to work on our understanding of machine learning concepts and try to put it into practise. Using the imagery provided by the professor we will create a dataframe with the lat, long, respective land use classification and relevant features of centroid point for each image. Land use classification is our target variable and the readings from the bands, as well as the derived features, will be used to create a model that would accurate identify land use classification in a new set up imager. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96cef0",
   "metadata": {},
   "source": [
    "While the band readings are nice, we do not need to let the machine do all the work. There are several indexes that have been proven to help identify land use classification. The following indexes will be created as additional features: \n",
    "\n",
    "1.\tNormalized Difference Vegetation Index (NDVI)- this versatile index is used in agriculture, natural hazards such as landslides, land use/land cover change detection, environmental monitoring, water resources etc. to name a few. NDVI provides valuable information in wide range of applications making it an important feature to be studied.\n",
    "NDVI = (B8-B4) / (B8+B4).\n",
    "\n",
    "2.\tSAVI- Soil Adjusted Vegetation Index (SAVI) is used to correct Normalized Difference Vegetation Index (NDVI) for the influence of soil brightness in areas where vegetative cover is low. The higher the NDVI values (the same stands for SAVI) the denser (and healthier) the vegetation. But NDVI start saturating after the value of 0.7, while SAVI at this point is only 0.3. This means that SAVI can be better used in dense vegetation because it saturates less fast. \n",
    "For Sentinel-2 the formula is:\n",
    "(B08 - B04) / (B08 + B04 + L) * (1.0 + L); L = 0.428\n",
    "where: L is a soil brightness correction factor ranging from 0 to 1\n",
    "L = 1 low vegetation cover, L = 0 high vegetation cover, L = 0.5 intermediate vegetation cover.\n",
    "https://custom-scripts.sentinel-hub.com/custom-scripts/sentinel-2/savi/\n",
    "\n",
    "3.\tNormalised difference water index (NDWI)- is used to highlight open water features in a satellite image, allowing a water body to “stand out” against the soil and vegetation. The downside of the index is that it is sensitive to built structures, which can lead to overestimation of water bodies.\n",
    "For Sentinel 2 data:\n",
    "NDWI= (Band 3 – Band 8)/(Band 3 + Band 8)\n",
    "NDWI: Index Formula, Value Range, And Uses In Agriculture (eos.com)\n",
    "\n",
    "The funtion below given in this section gets the NDVI, NDWI and SAVI for the centroid point of each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f3e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate NDVI, NDWI, and SAVI based on band values\n",
    "def calculate_indices(bands):\n",
    "    band4 = bands[3]  # Red\n",
    "    band3 = bands[2]  # Green\n",
    "    band8 = bands[7]  # NIR\n",
    "\n",
    "    # Define the formula constants for SAVI\n",
    "    L = 0.428\n",
    "    # calculate the indices\n",
    "    ndvi = (band8 - band4) / (band8 + band4)\n",
    "    ndwi = (band3 - band8) / (band3 + band8)\n",
    "    savi = (band8 - band4) / (band8 + band4 + L) * (1.0 + L)\n",
    "    return ndvi, ndwi, savi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d31de3",
   "metadata": {},
   "source": [
    "Right now we need to collect and create variables from the imagery to build out model. We wanted to include the max, median, range, and mode of all the band readings to have a broad understanding of what is going on at each observation point (centre coordinate). The funtion below reads all the tiff data and gets the data of the the centroid points of each image. The correspondentlat, lon, ndvi, ndwi, savi, max, min, range, mean and all band value are recorded for the centroid point of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read all tiff files into dataframe together with central coordinates and relevant features\n",
    "def read_data (directory_path):\n",
    "    # Build a datframe\n",
    "    data = pd.DataFrame(columns=[\"Lat\", \"Lon\", \"Lulc_class\", \"mean_val\", \"range_val\", \"median_val\", \"min_val\", \"max_val\", \"ndvi\", \"ndwi\", \"savi\",\n",
    "                             \"band1\", \"band2\", \"band3\", \"band4\", \"band5\", \"band6\", \"band7\", \"band8\", \"band9\", \"band10\", \"band11\", \"band12\"])\n",
    "    # Loop through the subfolders\n",
    "    for subdir in os.listdir(directory_path):\n",
    "        subfolder_path = os.path.join(directory_path, subdir)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "        # Get a list of all TIF files in the subfolder\n",
    "            tif_files = [file for file in os.listdir(subfolder_path) if file.endswith('.tif')]\n",
    "\n",
    "            for tif_file in tif_files:\n",
    "                tif_path = os.path.join(subfolder_path, tif_file)\n",
    "                # Read the raster file using rasterio\n",
    "                with rasterio.open(tif_path) as src:\n",
    "                    # Read and stack all bands into a single array\n",
    "                    bands = src.read()\n",
    "                    # Transfer the uint16 to int16\n",
    "                    bands = bands.astype(np.int16)\n",
    "\n",
    "                    # Get the center coordinates and  pixel location\n",
    "                    lon, lat = src.xy(src.width // 2, src.height // 2)\n",
    "                    row, col = src.index(lon, lat)\n",
    "                    bands = bands[:, row, col]\n",
    "                    # Extract LULC class from the subfolder name\n",
    "                    lulc_class = subdir\n",
    "\n",
    "                    # Calculate NDVI, NDWI, and SAVI based on band values\n",
    "                    ndvi, ndwi, savi = calculate_indices(bands)\n",
    "\n",
    "                    # Calculate the requested statistics\n",
    "                    mean_val = np.mean(bands)\n",
    "                    range_val = np.ptp(bands)\n",
    "                    median_val = np.median(bands)\n",
    "                    min_val = np.min(bands)\n",
    "                    max_val = np.max(bands)\n",
    "\n",
    "                    # Append the data to the DataFrame\n",
    "                    new_row = [lat, lon, lulc_class, mean_val, range_val,  median_val, min_val, max_val, ndvi, ndwi, savi, \n",
    "                            bands[0], bands[1], bands[2], bands[3], bands[4], bands[5], bands[6], bands[7],bands[8], bands[9], bands[10], bands[11]]\n",
    "                    data = pd.concat([data, pd.DataFrame([new_row], columns=data.columns)], ignore_index=True)\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177e922-2e76-4f62-9ac9-b7852ee7c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the images\n",
    "data = read_data(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc541bd-6446-4548-8e24-053a2ed93f25",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Split the data in training, test, and validation\n",
    "For our work it was important to have separate sets for training, validation, and testing. The primary reason was to reduce over fitting. The separation between these sets ensures that the model can perform well in real-world scenarios. Using the same data for all the three purposes can lead to over fitting as the model will simply memorize the data rather than making meaningful results. We chose to do K Fold cross validations for our work as it is less biased than the simple train/test/valid split. This method of spliting data will ideally not result in overfitting, while still being relativelly simple to implement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a8bbd-6c76-4101-b6b8-14535d880e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57febff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83946688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input and output data\n",
    "#X = data[['mean_val', 'range_val', 'median_val', 'min_val', 'max_val', 'ndvi', 'ndwi', 'savi']]\n",
    "X = data[['band1', 'band2', 'band3', 'band4', 'band5', 'band6', 'band7', 'band8', 'band9', 'band10', 'band11', 'band12']]\n",
    "#X = data.drop(['Lulc_class'], axis=1)\n",
    "y = data['Lulc_class']\n",
    "# Create the k-fold object\n",
    "k = 10\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069246e0",
   "metadata": {},
   "source": [
    "## 4. Developing our model\n",
    "Random forest is a well-known machine learning model, commonly used for classification tasks. In recent studies random forest model was found to out preform artificial neural networks with the same task of land use classification [1] When working with Sentinel-2 specifically, as we are here, random forest was found to be the stand out model for land use/land cover classification [2]. For these reasons we chose random forest as our model.\n",
    "\n",
    "[1] https://www.frontiersin.org/articles/10.3389/frai.2022.964279/full#:~:text=We%20classified%20land%20use%20and,conducted%20by%20Tan%20et%20al.\n",
    "\n",
    "[2] Ge, G., Shi, Z., Zhu, Y., Yang, X., & Hao, Y. (2020). Land use/cover classification in an arid desert-oasis mosaic landscape of China using remote sensed imagery: Performance assessment of four machine learning algorithms. Global Ecology and Conservation, 22, e00971. https://www.sciencedirect.com/science/article/pii/S2351989420300202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a2b984-57e1-4b0a-8da0-02faf3b27b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random forest classification model\n",
    "model = RandomForestClassifier(max_depth=5, random_state=95)\n",
    "# A list for accuaracy\n",
    "acc_score = []\n",
    " \n",
    "# Get the training and testing data using the k-fold object\n",
    "for train_index , test_index in kf.split(X):\n",
    "    X_train , X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train , y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    # Train the model\n",
    "    model.fit(X_train,y_train)\n",
    "    pred_values = model.predict(X_test)\n",
    "    # Calculate the accuracy of the model\n",
    "    acc = accuracy_score(pred_values,y_test)\n",
    "    acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9f323-eeda-4554-bc42-bd5cf27f3b02",
   "metadata": {},
   "source": [
    "## 5.Hyperparameter Optimization\n",
    "- Hyperparameter optimization is the process of finding the configuration of hyperparameters that results in the best performance. Hyperparameters are the variables that control the training process and the topology of an ML model. \n",
    "- The hyperparameters of a random forest model are the number of trees in the forest, the number of features to consider when looking for the best split, the maximum depth of the tree, the minimum number of samples required to split an internal node, the minimum number of samples required to be at a leaf node, and the number of features to consider when looking for the best split. \n",
    "- We used the RandomizedSearchCV and GridSearchCV function to find the best hyperparameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdadfa8-c909-476e-87bd-ef544d0f92f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90e7ecc",
   "metadata": {},
   "source": [
    "Randomized Search:\n",
    "- A big max_depth could produce over-fitted trees whule a small max_depth could lead to under-fitting. Considering about our feature number, the range of max_depth is set from 1 to 50.\n",
    "- Our model had around 10 features. There for the range of max_features was set to 1 to 10.\n",
    "- Min_sample_split is the minimum number of samples required to split an internal node. The range of min_sample_split was set to 2 to 10 as bigger number could lead to under-fitting and smaller number could lead to over-fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameters and distributions to sample from\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# define the parameter space that will be searched over\n",
    "param_dist = {\"max_depth\": [1,2,3,4,5,10,15,20,50,None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# iterate over the training dataset multiple times\n",
    "n_iter_search = 10\n",
    "\n",
    "# run randomized search\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=10)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with best parameters\n",
    "best_random = random_search.best_estimator_\n",
    "best_random.fit(X_train, y_train)\n",
    "pred_labels = best_random.predict(X_test)\n",
    "pa_mp = accuracy_score(y_test, pred_labels, normalize=False)\n",
    "print(\"Classification accuracy of RF (Random Search) is\", pa_mp/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866b2055",
   "metadata": {},
   "source": [
    "Grid Search:\n",
    "As grid search performs exhaustive search over specified parameter values for an estimator, we used the less range of values for max_depth, max_features and min_sample_split as we did for randomized search.\n",
    "<p><span style=\"color:red\">(The running process could be very long, please pay attention):</span></p>\n",
    "\n",
    "\n",
    "- A big max_depth could produce over-fitted trees whule a small max_depth could lead to under-fitting. Considering about our feature number, the range of max_depth is set from 1 to 50.\n",
    "- Our model had around 10 features. There for the range of max_features was set to 1 to 10.\n",
    "- Min_sample_split is the minimum number of samples required to split an internal node. The range of min_sample_split was set to 2 to 10 as bigger number could lead to under-fitting and smaller number could lead to over-fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f938497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter space that will be searched over\n",
    "param_grid = {\"max_depth\": [1,5,20,50,None],\n",
    "              \"max_features\": [3,5,10],\n",
    "              \"min_samples_split\": [2,5],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=10)\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c659608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model with best parameters\n",
    "best_grid = grid_search.best_estimator_\n",
    "best_grid.fit(X_train, X_test)\n",
    "pred_labels = best_grid.predict(y_train)\n",
    "pa_mp = accuracy_score(y_test, pred_labels, normalize=False)\n",
    "print(\"Classification accuracy of RF (Grid Search) is\", pa_mp/len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
